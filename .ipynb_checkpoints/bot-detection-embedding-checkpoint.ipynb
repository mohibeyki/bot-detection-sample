{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import keras\n",
    "import subprocess\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stems(line):\n",
    "    tokens = word_tokenize(line)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    porter = PorterStemmer()\n",
    "    stems = []\n",
    "    for t in tokens:\n",
    "        stems.append(porter.stem(t))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(stems, vocab):\n",
    "    seq = []\n",
    "    for stem in stems:\n",
    "        if stem in vocab:\n",
    "            seq.append(vocab[stem] - 1)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab():\n",
    "    with open('vocab.pickle', 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "        return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, vocab, maxlen, bot_file_name='tr-bot.txt', gen_file_name='tr-gen.txt', batch_size=64):\n",
    "        'Initialization'\n",
    "        self.bot_file_name = bot_file_name\n",
    "        self.gen_file_name = gen_file_name\n",
    "        self.vocab = vocab\n",
    "        self.maxlen = maxlen\n",
    "        self.size = int(subprocess.check_output(['wc', '-l', bot_file_name]).split()[0]) * 2\n",
    "        self.batch_size = batch_size\n",
    "        self.bot_file = open(self.bot_file_name, 'r', errors='ignore')\n",
    "        self.gen_file = open(self.gen_file_name, 'r', errors='ignore')\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.bot_file = open(self.bot_file_name, 'r', errors='ignore')\n",
    "        self.gen_file = open(self.gen_file_name, 'r', errors='ignore')\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(self.size / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        bot_data = []\n",
    "        for _ in range(int(self.batch_size / 2)):\n",
    "            bot_data.append(self.bot_file.readline())\n",
    "        gen_data = []\n",
    "        for _ in range(int(self.batch_size / 2)):\n",
    "            gen_data.append(self.gen_file.readline())\n",
    "\n",
    "        x_data = []\n",
    "        for line in bot_data:\n",
    "            stems = extract_stems(line)\n",
    "            x_data.append(get_one_hot(stems, vocab))\n",
    "        for line in gen_data:\n",
    "            stems = extract_stems(line)\n",
    "            x_data.append(get_one_hot(stems, vocab))\n",
    "        y_data = [1] * len(bot_data) + [0] * len(gen_data)\n",
    "\n",
    "        train_set = list(zip(x_data, y_data))\n",
    "        random.shuffle(train_set)\n",
    "        x, y = zip(*train_set)\n",
    "        x = sequence.pad_sequences(np.array(x), maxlen=self.maxlen)\n",
    "        return x, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(maxlen):\n",
    "    with open('test-bot.txt', 'r', errors='ignore') as file:\n",
    "        bot_data = file.readlines()\n",
    "\n",
    "    with open('test-gen.txt', 'r', errors='ignore') as file:\n",
    "        gen_data = file.readlines()\n",
    "\n",
    "    x_data = []\n",
    "    for line in bot_data:\n",
    "        stems = extract_stems(line)\n",
    "        x_data.append(get_one_hot(stems, vocab))\n",
    "    for line in gen_data:\n",
    "        stems = extract_stems(line)\n",
    "        x_data.append(get_one_hot(stems, vocab))\n",
    "    y_data = [1] * len(bot_data) + [0] * len(gen_data)\n",
    "    \n",
    "    x = sequence.pad_sequences(np.array(x_data), maxlen=maxlen)\n",
    "    return x, np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 20000\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "batch_size = 64\n",
    "vocab = load_vocab()\n",
    "print('vocab size:', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(vocab, maxlen, 'tr-bot.txt', 'tr-gen.txt', batch_size)\n",
    "validation_generator = DataGenerator(vocab, maxlen, 'val-bot.txt', 'val-gen.txt', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab), 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = get_test_data(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4095/4095 [==============================] - 217s 53ms/step - loss: 0.0781 - acc: 0.9706 - val_loss: 0.0179 - val_acc: 0.9928\n",
      "Epoch 2/10\n",
      "4095/4095 [==============================] - 215s 52ms/step - loss: 0.0520 - acc: 0.9803 - val_loss: 0.0170 - val_acc: 0.9927\n",
      "Epoch 3/10\n",
      "4095/4095 [==============================] - 215s 52ms/step - loss: 0.0403 - acc: 0.9849 - val_loss: 0.0151 - val_acc: 0.9934\n",
      "Epoch 4/10\n",
      "4095/4095 [==============================] - 215s 52ms/step - loss: 0.0350 - acc: 0.9872 - val_loss: 0.0150 - val_acc: 0.9935\n",
      "Epoch 5/10\n",
      "4095/4095 [==============================] - 215s 52ms/step - loss: 0.0320 - acc: 0.9884 - val_loss: 0.0145 - val_acc: 0.9934\n",
      "Epoch 6/10\n",
      "4095/4095 [==============================] - 215s 52ms/step - loss: 0.0318 - acc: 0.9883 - val_loss: 0.0145 - val_acc: 0.9935\n",
      "Epoch 7/10\n",
      "4095/4095 [==============================] - 215s 53ms/step - loss: 0.0294 - acc: 0.9891 - val_loss: 0.0143 - val_acc: 0.9936\n",
      "Epoch 8/10\n",
      "4095/4095 [==============================] - 215s 52ms/step - loss: 0.0277 - acc: 0.9899 - val_loss: 0.0143 - val_acc: 0.9937\n",
      "Epoch 9/10\n",
      "4095/4095 [==============================] - 215s 52ms/step - loss: 0.0261 - acc: 0.9903 - val_loss: 0.0152 - val_acc: 0.9936\n",
      "Epoch 10/10\n",
      "4095/4095 [==============================] - 215s 53ms/step - loss: 0.0260 - acc: 0.9905 - val_loss: 0.0141 - val_acc: 0.9938\n",
      "16384/16384 [==============================] - 3s 188us/step\n",
      "Test score: 0.8558729576389283\n",
      "Test accuracy: 0.908935546875\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    workers=1,\n",
    "                    epochs=10)\n",
    "\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                           batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
